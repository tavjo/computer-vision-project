{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2024 Coding Challenge: Automated Object Detection and Counting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Objective:** Develop a Python-based application that uses computer vision techniques to count and classify different objects from a set of images. The system should be able to differentiate at least three types of objects (e.g., cars, bicycles, pedestrians) in diverse lighting and background conditions. \n",
    "\n",
    "**Resources:** \n",
    "- https://docs.ultralytics.com/yolov5/tutorials/train_custom_data/#clearml-logging-and-automation-new\n",
    "- https://github.com/ultralytics/yolov5/blob/master/tutorial.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Download Data:\n",
    "- Run the download_data.py script to download the dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Download Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run 'download_data.py script' to download and get COCO dataset\n",
    "# examine 5 images\n",
    "%run ./../scripts/download_data.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transfer to google drive**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp -r data/raw/ \"/Users/taishajoseph/Library/CloudStorage/GoogleDrive-taishavj28@gmail.com/My Drive/computer-vision-project/data/raw/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not change this code\n",
    "!pip install --upgrade --no-cache-dir gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir /content/data/\n",
    "!mkdir /content/data/filtered/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def generate_direct_download_link(shared_link):\n",
    "    \"\"\"\n",
    "    Generates a direct download link from a shared Google Drive link.\n",
    "\n",
    "    Args:\n",
    "        shared_link (str): The shared Google Drive link.\n",
    "\n",
    "    Returns:\n",
    "        str: The direct download link or an error message.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If the provided link is not a valid Google Drive shared link.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Check if the shared link is a valid Google Drive link\n",
    "        if \"drive.google.com/file/d/\" not in shared_link:\n",
    "            raise ValueError(\"The provided link is not a valid Google Drive shared link.\")\n",
    "        \n",
    "        # Extract the file ID from the shared link\n",
    "        file_id = shared_link.split('/d/')[1].split('/')[0]\n",
    "        \n",
    "        # Create the direct download link\n",
    "        direct_download_link = f\"https://drive.google.com/uc?export=download&id={file_id}\"\n",
    "        \n",
    "        return direct_download_link\n",
    "    except Exception as e:\n",
    "        return f\"An error occurred: {e}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val2017 = \"https://drive.google.com/file/d/18rji_6JgJYIBfv7EY2PQP3nQA689ZR2I/view?usp=sharing\"\n",
    "train2017 = \"https://drive.google.com/file/d/1RgUrTkclcqtT8FVl912XCzX3jIahQwBU/view?usp=sharing\"\n",
    "annotations_trainval2017 = \"https://drive.google.com/file/d/10oTb3FBJbWz7ZKjw2G-udamNMCBfYtuF/view?usp=sharing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn shared google drive shared link to direct download link\n",
    "train2017 = generate_direct_download_link(train2017)\n",
    "val2017 = generate_direct_download_link(val2017)\n",
    "annotations_trainval2017 = generate_direct_download_link(annotations_trainval2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export zip data files from google drive\n",
    "!gdown {train2017} -O /tmp/train2017.zip\n",
    "!gdown {val2017} -O /tmp/val2017.zip\n",
    "!gdown {annotations_trainval2017} -O /tmp/annotations_trainval2017.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Data\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "local_zip = '/tmp/train2017.zip'\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall('/tmp')\n",
    "local_zip = '/tmp/val2017.zip'\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall('/tmp')\n",
    "local_zip = '/tmp/test.zip'\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall('/tmp/annotations_trainval2017.zip')\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Prep Data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1. Filter COCO Annotations\n",
    "- We'll create a Python script to filter the annotations for the classes person, car, and bicycle. \n",
    "- In this section, we will update the annotations and copy the relevant images to a new directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- *Load the COCO annotations using COCO(input_annotation_file).*\n",
    "\n",
    "    - Get category IDs for the classes of interest using getCatIds(catNms=categories_to_keep).\n",
    "    - Get image IDs associated with the filtered categories using getImgIds(catIds=category_ids).\n",
    "\n",
    "- *Filtering Process:*\n",
    "\n",
    "    - Iterate over the filtered image IDs.\n",
    "    - Load image information and corresponding annotations.\n",
    "    - Append filtered images and annotations to the respective lists.\n",
    "    - Copy relevant images to the output directory.\n",
    "\n",
    "- *Saving Filtered Data:*\n",
    "\n",
    "    - Save the filtered images, annotations, and categories to the output annotation file in COCO format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import json\n",
    "from pycocotools.coco import COCO\n",
    "\n",
    "def ensure_dir_exists(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "def filter_coco_annotations(input_annotation_file, output_annotation_file, image_dir, output_image_dir, categories_to_keep):\n",
    "    coco = COCO(input_annotation_file)\n",
    "    category_ids = coco.getCatIds(catNms=categories_to_keep)\n",
    "    image_ids = coco.getImgIds(catIds=category_ids)\n",
    "    \n",
    "    filtered_annotations = []\n",
    "    filtered_images = []\n",
    "\n",
    "    ensure_dir_exists(output_image_dir)\n",
    "    ensure_dir_exists(os.path.dirname(output_annotation_file))\n",
    "\n",
    "    for img_id in image_ids:\n",
    "        img_info = coco.loadImgs(img_id)[0]\n",
    "        ann_ids = coco.getAnnIds(imgIds=img_id, catIds=category_ids)\n",
    "        anns = coco.loadAnns(ann_ids)\n",
    "\n",
    "        filtered_images.append(img_info)\n",
    "        filtered_annotations.extend(anns)\n",
    "\n",
    "        # Copy image to output directory\n",
    "        src_img_path = os.path.join(image_dir, img_info['file_name'])\n",
    "        dst_img_path = os.path.join(output_image_dir, img_info['file_name'])\n",
    "        shutil.copy(src_img_path, dst_img_path)\n",
    "    \n",
    "    filtered_data = {\n",
    "        'images': filtered_images,\n",
    "        'annotations': filtered_annotations,\n",
    "        'categories': [cat for cat in coco.loadCats(category_ids)]\n",
    "    }\n",
    "\n",
    "    with open(output_annotation_file, 'w') as f:\n",
    "        json.dump(filtered_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=31.63s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "categories_to_keep = ['person', 'car', 'bicycle']\n",
    "\n",
    "filter_coco_annotations(\n",
    "    './../data/raw/coco_annotations/annotations/instances_train2017.json',\n",
    "    './../data/filtered/annotations/filtered_instances_train2017.json',\n",
    "    './../data/raw/coco_train2017/train2017',\n",
    "    './../data/filtered/images/train2017',\n",
    "    categories_to_keep\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.77s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "filter_coco_annotations(\n",
    "    './../data/raw/coco_annotations/annotations/instances_val2017.json',\n",
    "    './../data/filtered/annotations/filtered_instances_val2017.json',\n",
    "    './../data/raw/coco_val2017/val2017/val2017',\n",
    "    './../data/filtered/images/val2017',\n",
    "    categories_to_keep\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1. Organize Dataset Directory\n",
    "After filtering, we'll organize the dataset directory structure to be compatible with YOLOv5.\n",
    "Right now, the dataset directory should look like this:\n",
    "\n",
    "- data/\n",
    "  - filtered/\n",
    "    - images/\n",
    "      - train2017/\n",
    "      - val2017/\n",
    "    - annotations/\n",
    "      - filtered_instances_train2017.json\n",
    "      - filtered_instances_val2017.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2. Convert COCO Annotations to YOLO Format\n",
    "We need to convert the filtered COCO annotations to YOLO format (i.e., .txt files for each image)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_coco_to_yolo(annotations_file, labels_dir):\n",
    "    # Load the COCO annotations file\n",
    "    with open(annotations_file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # Create a dictionary to map category IDs to category names\n",
    "    categories = {cat['id']: cat['name'] for cat in data['categories']}\n",
    "    \n",
    "    # Create a dictionary to map category names to YOLO class indices\n",
    "    category_to_index = {name: index for index, name in enumerate(categories.values())}\n",
    "\n",
    "    # Ensure the labels directory exists\n",
    "    os.makedirs(labels_dir, exist_ok=True)\n",
    "\n",
    "    # Iterate over all annotations in the COCO dataset\n",
    "    for ann in data['annotations']:\n",
    "        image_id = ann['image_id']\n",
    "        category_id = ann['category_id']\n",
    "        bbox = ann['bbox']\n",
    "        category_name = categories[category_id]\n",
    "\n",
    "        # Skip categories that are not in the category_to_index dictionary\n",
    "        if category_name not in category_to_index:\n",
    "            continue\n",
    "\n",
    "        # Get image information to calculate normalized bounding box coordinates\n",
    "        image_info = next(img for img in data['images'] if img['id'] == image_id)\n",
    "        image_width = image_info['width']\n",
    "        image_height = image_info['height']\n",
    "\n",
    "        # Calculate YOLO format coordinates (normalized)\n",
    "        x_center = (bbox[0] + bbox[2] / 2) / image_width\n",
    "        y_center = (bbox[1] + bbox[3] / 2) / image_height\n",
    "        width = bbox[2] / image_width\n",
    "        height = bbox[3] / image_height\n",
    "\n",
    "        # Create the YOLO label string\n",
    "        yolo_label = f\"{category_to_index[category_name]} {x_center} {y_center} {width} {height}\\n\"\n",
    "\n",
    "        # Determine the label file path based on the image file name (without extension)\n",
    "        label_file_path = os.path.join(labels_dir, f\"{image_info['file_name'].split('.')[0]}.txt\")\n",
    "        \n",
    "        # Append the YOLO label to the label file\n",
    "        with open(label_file_path, 'a') as label_file:\n",
    "            label_file.write(yolo_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_coco_to_yolo(\n",
    "    './../data/filtered/annotations/filtered_instances_train2017.json',\n",
    "    # 'data/filtered/images/train2017',\n",
    "    './../data/filtered/labels/train2017'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_coco_to_yolo(\n",
    "    './../data/filtered/annotations/filtered_instances_val2017.json',\n",
    "    # 'data/filtered/images/val2017',\n",
    "    './../data/filtered/labels/val2017'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right now, the dataset directory should look like this:\n",
    "\n",
    "- data/\n",
    "  - filtered/\n",
    "    - images/\n",
    "      - train2017/\n",
    "      - val2017/\n",
    "    - annotations/\n",
    "      - filtered_instances_train2017.json\n",
    "      - filtered_instances_val2017.json\n",
    "    - labels/\n",
    "      - train2017/\n",
    "      - val2017/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Before moving on to training a model:**\n",
    "\n",
    "Step 1: Setting Up the Environment\n",
    "\n",
    "- clone YOLOv5 repository\n",
    "- install requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://github.com/ultralytics/yolov5\n",
    "# !cd yolov5\n",
    "# %pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: YOLOv5 Data Configuration\n",
    "- Create a YOLOv5 data configuration file titled: \"coco_person_car_bicycle.yaml\"\n",
    "- cp configuration file to base directory of YOLOv5 repo where the train.py script is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !cp coco_person_car_bicycle.yaml ~/Documents/Projects/yolov5/coco_person_car_bicycle.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpoint 1: Clear Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear variables\n",
    "%reset -f\n",
    "\n",
    "# Import necessary libraries\n",
    "import gc\n",
    "\n",
    "# Run garbage collector\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train\n",
    "**2 Options for training a model with YOLOv5:**\n",
    "\n",
    "- Fine-tune a pre-trained model with pre-exisiting weights\n",
    "- Train a model from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model (smallest one is yolov5n) from scratch\n",
    "Should be in *~/Documents/Projects/yolov5/* directory\n",
    "\n",
    "- Navigate to the models folder in the cloned yolov5 repo\n",
    "- Modify the \"yolov5n.yaml\" file by replacing the number of classes from 80 to 3\n",
    "- Adjust other parameters for each layer of the model as needed. (Let's start with the default parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define parameters for training:**\n",
    "\n",
    "- img 640: Use 640x640 images for training.\n",
    "- batch 16: Use a batch size of 16.\n",
    "- epochs 50: Train for 50 epochs.\n",
    "- data coco_person_car_bicycle.yaml: Use custom data configuration file with fewer classes.\n",
    "- weights '': Train from scratch by not using any pre-trained weights.\n",
    "- cfg yolov5n.yaml: Use the configuration file for YOLOv5n (the smallest model). --> \"models/yolov5n.yaml\"\n",
    "- device 0: Use the first GPU for training.\n",
    "--project:Directory where results will be saved. (\"/Users/taishajoseph/Documents/Projects/computer-vision-project/yolov5n/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Recommended:** run in terminal\n",
    "\n",
    "**If running in Jupyter notebook, be sure to clear the notebook memory first**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#Define parameters for training:\n",
    "data_config=\"coco_person_car_bicycle.yaml\"\n",
    "config=\"yolov5n.yaml\"\n",
    "out_dir = \"/Users/taishajoseph/Documents/Projects/computer-vision-project/yolov5n/train/\"\n",
    "os.makedirs(out_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #example run in terminal (don't run):\n",
    "# cd .. #navigate to computer vision project root directory\n",
    "\n",
    "# mkdir yolov5n #create yolov5n directory\n",
    "\n",
    "# mkdir /Users/taishajoseph/Documents/Projects/computer-vision-project/yolov5n/train/ #create train subdirectory\n",
    "\n",
    "# cd ~/Documents/Projects/yolov5 #navigate to yolov5 project directory\n",
    "\n",
    "# python train.py --img 640 --batch 16 --epochs 50 --data coco_person_car_bicycle.yaml --weights '' --cfg yolov5n.yaml --device 0 --project /Users/taishajoseph/Documents/Projects/computer-vision-project/yolov5n/train/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run as subprocess\n",
    "!cd ~/Documents/Projects/yolov5\n",
    "%run train.py --img 640 --batch 16 --epochs 50 --data coco_person_car_bicycle.yaml --weights '' --cfg {config} --device cpu --project {out_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finetune pre-trained model\n",
    "# python train.py --img 640 --batch 8 --epochs 10 --data coco_person_car_bicycle.yaml --weights yolov5s.pt --cfg yolov5n.yaml --device cpu --project /Users/taishajoseph/Documents/Projects/computer-vision-project/yolov5n/train/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpoint 2: Clear Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear variables\n",
    "%reset -f\n",
    "\n",
    "# Import necessary libraries\n",
    "import gc\n",
    "\n",
    "# Run garbage collector\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate\n",
    "Should be in *~/Documents/Projects/yolov5/* directory\n",
    "\n",
    "**Recommended:** run in terminal\n",
    "\n",
    "**If running in Jupyter notebook, be sure to clear the notebook memory first**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate the trained model on the validation dataset:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "out_dir = \"/Users/taishajoseph/Documents/Projects/computer-vision-project/yolov5n/train/\"\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "data_config=\"coco_person_car_bicycle.yaml\"\n",
    "wts = os.path.join(out_dir, \"exp/weights/best.pt\")\n",
    "wts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python val.py --data \"coco_person_car_bicycle.yaml\" --weights \"runs/train/exp/weights/best.pt\" --cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run as subprocess\n",
    "!cd ~/Documents/Projects/yolov5\n",
    "%run val.py --data {data_config} --weights {wts}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpoint 3: Clear Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear variables\n",
    "%reset -f\n",
    "\n",
    "# Import necessary libraries\n",
    "import gc\n",
    "\n",
    "# Run garbage collector\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = \"/Users/taishajoseph/Documents/Projects/computer-vision-project/yolov5n/train/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "results = os.path.join(out_dir, \"results.csv\")\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd ~/Documents/Projects/yolov5\n",
    "from utils.plots import plot_results\n",
    "\n",
    "plot_results(results)  # plot 'results.csv' as 'results.png'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skynavai_challenge",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
